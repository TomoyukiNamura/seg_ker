Tensor("max_pooling2d_1/MaxPool:0", shape=(?, 180, 240, 64), dtype=float32)
Tensor("max_pooling2d_2/MaxPool:0", shape=(?, 90, 120, 128), dtype=float32)
Tensor("max_pooling2d_3/MaxPool:0", shape=(?, 45, 60, 256), dtype=float32)
Tensor("activation_4/Relu:0", shape=(?, 45, 60, 512), dtype=float32)
Tensor("activation_5/Relu:0", shape=(?, 45, 60, 512), dtype=float32)
Tensor("activation_6/Relu:0", shape=(?, 90, 120, 256), dtype=float32)
Tensor("activation_7/Relu:0", shape=(?, 180, 240, 128), dtype=float32)
Tensor("activation_8/Relu:0", shape=(?, 360, 480, 64), dtype=float32)
Tensor("activation_9/truediv:0", shape=(?, 172800, 12), dtype=float32)



name: "segnet"
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  dense_image_data_param {
    source: "/SegNet/CamVid/train.txt"	# Change this to the absolute path to your data file
    batch_size: 4   			# Change this number to a batch size that will fit on your GPU
    shuffle: true
  }
}
layer {
  name: "norm"
  type: "LRN"
  bottom: "data"
  top: "norm"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}



# 1========================================================

    x = Conv2D(64, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

layer {
  name: "conv1"
  type: "Convolution"
  bottom: "norm"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv1"
  top: "conv1"
  name: "conv1_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}




# 2========================================================
    x = Conv2D(128, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv2"
  top: "conv2"
  name: "conv2_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}

layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}



# 3========================================================
    x = Conv2D(256, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)


layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv3"
  top: "conv3"
  name: "conv3_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}

layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}



# 4========================================================
    x = Conv2D(512, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv4"
  top: "conv4"
  name: "conv4_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}

layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}



# -4========================================================
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(512, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)

layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "pool4"
  bottom: "pool4_mask"
  top: "upsample4"
  upsample_param {
    scale: 2
    pad_out_h: true
  }
}

layer {
  name: "conv_decode4"
  type: "Convolution"
  bottom: "upsample4"
  top: "conv_decode4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv_decode4"
  top: "conv_decode4"
  name: "conv_decode4_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}


# -3========================================================
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(256, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)

layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv_decode4"
  bottom: "pool3_mask"
  top: "upsample3"
  upsample_param {
    scale: 2
  }
}

layer {
  name: "conv_decode3"
  type: "Convolution"
  bottom: "upsample3"
  top: "conv_decode3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv_decode3"
  top: "conv_decode3"
  name: "conv_decode3_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}



# -2========================================================
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(128, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)


layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv_decode3"
  bottom: "pool2_mask"
  top: "upsample2"
  upsample_param {
    scale: 2
  }
}
 
layer {
  name: "conv_decode2"
  type: "Convolution"
  bottom: "upsample2"
  top: "conv_decode2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv_decode2"
  top: "conv_decode2"
  name: "conv_decode2_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}


# -1========================================================
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(64, (3, 3), padding="same")(x)
    x = BatchNormalization()(x)

layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv_decode2"
  bottom: "pool1_mask"
  top: "upsample1"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv_decode1"
  type: "Convolution"
  bottom: "upsample1"
  top: "conv_decode1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  bottom: "conv_decode1"
  top: "conv_decode1"
  name: "conv_decode1_bn"
  type: "BN"
  bn_param {
	scale_filler {
	  type: "constant"
	  value: 1
	}
	shift_filler {
	  type: "constant"
	  value: 0.001
	}
 }
}


# 出力========================================================
    x = Conv2D(classes, (1, 1), padding="valid")(x)
    x = Reshape((input_shape[0] * input_shape[1], classes))(x)
    x = Activation("softmax")(x)
    
    
layer {
  name: "conv_classifier"
  type: "Convolution"
  bottom: "conv_decode1"
  top: "conv_classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 11
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv_classifier"
  bottom: "label"
  top: "loss"
  softmax_param {engine: CAFFE}
  loss_param: {
    weight_by_label_freqs: true
    ignore_label: 11
    class_weighting: 0.2595
    class_weighting: 0.1826
    class_weighting: 4.5640
    class_weighting: 0.1417
    class_weighting: 0.9051
    class_weighting: 0.3826
    class_weighting: 9.6446
    class_weighting: 1.8418
    class_weighting: 0.6823
    class_weighting: 6.2478
    class_weighting: 7.3614
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv_classifier"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
